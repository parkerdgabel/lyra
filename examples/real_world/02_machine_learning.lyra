(*
==============================================================================
MACHINE LEARNING SYSTEM - END-TO-END ML WORKFLOW
==============================================================================

A comprehensive machine learning system demonstrating Lyra's ML capabilities:
- Dataset preparation and preprocessing
- Neural network architecture design
- Training loops with optimization
- Model evaluation and metrics
- Hyperparameter tuning
- Model deployment and inference

This example builds a deep learning model for image classification with
production-ready features like checkpointing, early stopping, and model
versioning.
==============================================================================
*)

(* =========================== CONFIGURATION =========================== *)

(* ML training configuration *)
config = {
    "datasetPath" -> "data/cifar10",
    "batchSize" -> 128,
    "epochs" -> 100,
    "learningRate" -> 0.001,
    "validationSplit" -> 0.2,
    "enableGPU" -> True,
    "enableMixedPrecision" -> True,
    "checkpointFreq" -> 10,
    "earlyStoppingPatience" -> 10,
    "randomSeed" -> 42
};

(* Model architecture configuration *)
modelConfig = {
    "inputShape" -> {32, 32, 3},
    "numClasses" -> 10,
    "architecture" -> "ResNet18",
    "dropout" -> 0.3,
    "batchNorm" -> True,
    "activation" -> "ReLU"
};

(* Hyperparameter search space *)
hyperparamSpace = {
    "learningRate" -> {0.0001, 0.001, 0.01},
    "batchSize" -> {64, 128, 256},
    "dropout" -> {0.2, 0.3, 0.5},
    "optimizer" -> {"Adam", "SGD", "RMSprop"}
};

(* =========================== DATA PREPROCESSING =========================== *)

(* Comprehensive data preprocessing pipeline *)
PrepareDataset[dataPath_String, config_Association] := Module[
    {rawData, trainData, valData, testData, normalizedData, augmentedData},
    
    Log["INFO", "Loading dataset from: " <> dataPath];
    
    (* Load raw data *)
    rawData = Import[dataPath <> "/train.csv"];
    testData = Import[dataPath <> "/test.csv"];
    
    (* Parse data into images and labels *)
    trainImages = Map[ArrayReshape[#, modelConfig["inputShape"]] &, 
                     rawData[[All, 2;;]]];
    trainLabels = rawData[[All, 1]];
    
    testImages = Map[ArrayReshape[#, modelConfig["inputShape"]] &, 
                    testData[[All, 2;;]]];
    
    (* Normalize pixel values to [0, 1] *)
    normalizedTrain = Map[# / 255.0 &, trainImages];
    normalizedTest = Map[# / 255.0 &, testImages];
    
    (* Split into train/validation sets *)
    splitIndex = Floor[Length[normalizedTrain] * (1 - config["validationSplit"])];
    
    {trainData, valData} = {
        {Take[normalizedTrain, splitIndex], Take[trainLabels, splitIndex]},
        {Drop[normalizedTrain, splitIndex], Drop[trainLabels, splitIndex]}
    };
    
    (* Data augmentation for training set *)
    augmentedTrain = DataAugmentation[trainData[[1]], {
        "rotation" -> 15,
        "horizontalFlip" -> True,
        "zoom" -> 0.1,
        "shear" -> 0.1,
        "brightness" -> 0.2,
        "contrast" -> 0.2
    }];
    
    Log["INFO", "Dataset prepared - Train: " <> ToString[Length[augmentedTrain]] <>
                ", Val: " <> ToString[Length[valData[[1]]]] <>
                ", Test: " <> ToString[Length[normalizedTest]]];
    
    {
        "train" -> {augmentedTrain, trainData[[2]]},
        "validation" -> valData,
        "test" -> {normalizedTest, trainLabels}, (* Placeholder labels for test *)
        "classes" -> Range[0, modelConfig["numClasses"] - 1],
        "inputShape" -> modelConfig["inputShape"]
    }
];

(* Advanced data augmentation *)
DataAugmentation[images_List, augmentParams_Association] := Module[
    {augmented, transforms},
    
    Log["INFO", "Applying data augmentation"];
    
    transforms = {};
    
    (* Rotation *)
    If[KeyExistsQ[augmentParams, "rotation"],
        AppendTo[transforms, 
            Function[img, ImageRotate[img, RandomReal[{-augmentParams["rotation"], 
                                                     augmentParams["rotation"]}]]]
        ]
    ];
    
    (* Horizontal flip *)
    If[KeyExistsQ[augmentParams, "horizontalFlip"] && augmentParams["horizontalFlip"],
        AppendTo[transforms, 
            Function[img, If[RandomReal[] > 0.5, ImageReflect[img, "Horizontal"], img]]
        ]
    ];
    
    (* Zoom *)
    If[KeyExistsQ[augmentParams, "zoom"],
        AppendTo[transforms,
            Function[img, ImageResize[img, 
                RandomReal[{1 - augmentParams["zoom"], 1 + augmentParams["zoom"]}]]]
        ]
    ];
    
    (* Apply transforms *)
    augmented = Map[
        Function[img,
            Fold[#2[#1] &, img, transforms]
        ],
        images
    ];
    
    Join[images, augmented] (* Return original + augmented *)
];

(* =========================== MODEL ARCHITECTURE =========================== *)

(* Build ResNet-18 architecture *)
BuildResNet18[inputShape_List, numClasses_Integer, dropout_Real] := Module[
    {model, residualBlock},
    
    Log["INFO", "Building ResNet-18 architecture"];
    
    (* Define residual block *)
    residualBlock[channels_Integer, stride_Integer:1] := Sequential[{
        (* First convolution block *)
        Sequential[{
            Conv2D[channels, {3, 3}, "stride" -> stride, "padding" -> "same"],
            BatchNormalization[],
            ReLU[],
            
            Conv2D[channels, {3, 3}, "stride" -> 1, "padding" -> "same"],
            BatchNormalization[]
        }],
        
        (* Skip connection *)
        If[stride != 1,
            Conv2D[channels, {1, 1}, "stride" -> stride, "padding" -> "same"],
            Identity[]
        ],
        
        (* Add and activate *)
        Add[],
        ReLU[]
    }];
    
    (* Build full ResNet-18 *)
    model = Sequential[{
        (* Initial convolution *)
        Conv2D[64, {7, 7}, "stride" -> 2, "padding" -> "same"],
        BatchNormalization[],
        ReLU[],
        MaxPooling2D[{3, 3}, "stride" -> 2, "padding" -> "same"],
        
        (* Residual blocks *)
        residualBlock[64],
        residualBlock[64],
        
        residualBlock[128, 2],
        residualBlock[128],
        
        residualBlock[256, 2],
        residualBlock[256],
        
        residualBlock[512, 2],
        residualBlock[512],
        
        (* Classifier head *)
        GlobalAveragePooling2D[],
        Dropout[dropout],
        Dense[numClasses],
        Softmax[]
    }];
    
    Log["INFO", "ResNet-18 model built with " <> ToString[CountParameters[model]] <> " parameters"];
    model
];

(* Alternative: Build Vision Transformer *)
BuildVisionTransformer[inputShape_List, numClasses_Integer, patchSize_Integer:16] := Module[
    {model, patchEmbed, posEmbed, transformer},
    
    Log["INFO", "Building Vision Transformer"];
    
    (* Patch embedding *)
    patchEmbed = Sequential[{
        Reshape[{inputShape[[1]] / patchSize, inputShape[[2]] / patchSize, patchSize * patchSize * inputShape[[3]]}],
        Dense[768]  (* Embedding dimension *)
    }];
    
    (* Positional embedding *)
    posEmbed = PositionalEncoding[768];
    
    (* Transformer blocks *)
    transformer = Sequential[
        Table[
            Sequential[{
                LayerNormalization[],
                MultiHeadAttention[12, 64],  (* 12 heads, 64-dim keys *)
                Add[],  (* Skip connection *)
                
                LayerNormalization[],
                Sequential[{Dense[3072], GELU[], Dense[768]}],  (* MLP *)
                Add[]  (* Skip connection *)
            }),
            {i, 12}  (* 12 transformer layers *)
        ]
    ];
    
    (* Full ViT model *)
    model = Sequential[{
        patchEmbed,
        posEmbed,
        transformer,
        LayerNormalization[],
        GlobalAveragePooling1D[],
        Dense[numClasses],
        Softmax[]
    }];
    
    Log["INFO", "Vision Transformer built with " <> ToString[CountParameters[model]] <> " parameters"];
    model
];

(* =========================== TRAINING LOOP =========================== *)

(* Advanced training loop with all production features *)
TrainModel[model_, dataset_Association, config_Association] := Module[
    {optimizer, lossFunction, metrics, history, bestValLoss, patienceCounter, 
     mixedPrecisionScaler, checkpointManager, trainingStartTime},
    
    Log["INFO", "Starting model training"];
    trainingStartTime = AbsoluteTime[];
    
    (* Initialize training components *)
    optimizer = Switch[config["optimizer"],
        "Adam", Adam["learningRate" -> config["learningRate"]],
        "SGD", SGD["learningRate" -> config["learningRate"], "momentum" -> 0.9],
        "RMSprop", RMSprop["learningRate" -> config["learningRate"]],
        _, Adam["learningRate" -> config["learningRate"]]
    ];
    
    lossFunction = CategoricalCrossentropy[];
    metrics = {Accuracy[], Precision[], Recall[], F1Score[]};
    
    (* Mixed precision training *)
    If[config["enableMixedPrecision"],
        mixedPrecisionScaler = GradScaler[];
    ];
    
    (* Checkpoint manager *)
    checkpointManager = CheckpointManager["./checkpoints/model"];
    
    (* Initialize tracking variables *)
    history = {"trainLoss" -> {}, "valLoss" -> {}, "trainAcc" -> {}, "valAcc" -> {}};
    bestValLoss = Infinity;
    patienceCounter = 0;
    
    (* Training loop *)
    Do[
        Module[{epochStartTime, trainLoss, trainMetrics, valLoss, valMetrics, 
                learningRate, earlyStop},
            
            epochStartTime = AbsoluteTime[];
            Log["INFO", "Epoch " <> ToString[epoch] <> "/" <> ToString[config["epochs"]]];
            
            (* Training phase *)
            model.SetTraining[True];
            {trainLoss, trainMetrics} = TrainEpoch[model, dataset["train"], 
                                                  optimizer, lossFunction, metrics, 
                                                  config, mixedPrecisionScaler];
            
            (* Validation phase *)
            model.SetTraining[False];
            {valLoss, valMetrics} = ValidateEpoch[model, dataset["validation"], 
                                                 lossFunction, metrics];
            
            (* Update history *)
            AppendTo[history["trainLoss"], trainLoss];
            AppendTo[history["valLoss"], valLoss];
            AppendTo[history["trainAcc"], trainMetrics["accuracy"]];
            AppendTo[history["valAcc"], valMetrics["accuracy"]];
            
            (* Learning rate scheduling *)
            learningRate = optimizer.GetLearningRate[];
            If[epoch > 30 && valLoss > Last[history["valLoss"], 5],
                optimizer.SetLearningRate[learningRate * 0.5];
                Log["INFO", "Reduced learning rate to: " <> ToString[learningRate * 0.5]];
            ];
            
            (* Early stopping *)
            If[valLoss < bestValLoss,
                bestValLoss = valLoss;
                patienceCounter = 0;
                (* Save best model *)
                checkpointManager.Save[model, "best_model"];
            ,
                patienceCounter++;
                If[patienceCounter >= config["earlyStoppingPatience"],
                    Log["INFO", "Early stopping triggered after " <> ToString[epoch] <> " epochs"];
                    earlyStop = True;
                ]
            ];
            
            (* Periodic checkpointing *)
            If[Mod[epoch, config["checkpointFreq"]] == 0,
                checkpointManager.Save[model, "epoch_" <> ToString[epoch]];
            ];
            
            (* Log epoch results *)
            epochTime = AbsoluteTime[] - epochStartTime;
            Log["INFO", StringTemplate["Epoch `epoch` - Train Loss: `trainLoss`, Val Loss: `valLoss`, Train Acc: `trainAcc`%, Val Acc: `valAcc`%, Time: `time`s"][{
                "epoch" -> epoch,
                "trainLoss" -> Round[trainLoss, 0.0001],
                "valLoss" -> Round[valLoss, 0.0001],
                "trainAcc" -> Round[trainMetrics["accuracy"] * 100, 0.1],
                "valAcc" -> Round[valMetrics["accuracy"] * 100, 0.1],
                "time" -> Round[epochTime, 0.1]
            }]];
            
            (* Break if early stopping *)
            If[earlyStop === True, Break[]]
        ],
        {epoch, 1, config["epochs"]}
    ];
    
    totalTrainingTime = AbsoluteTime[] - trainingStartTime;
    Log["INFO", "Training completed in " <> ToString[Round[totalTrainingTime / 60, 0.1]] <> " minutes"];
    
    (* Load best model *)
    bestModel = checkpointManager.Load["best_model"];
    
    {
        "model" -> bestModel,
        "history" -> history,
        "bestValLoss" -> bestValLoss,
        "totalEpochs" -> Length[history["trainLoss"]],
        "trainingTime" -> totalTrainingTime
    }
];

(* Training epoch with gradient accumulation *)
TrainEpoch[model_, trainData_, optimizer_, lossFunction_, metrics_, config_, scaler_:Null] := Module[
    {totalLoss, totalMetrics, batchCount, accumulationSteps},
    
    totalLoss = 0.0;
    totalMetrics = Map[0.0 &, metrics];
    batchCount = 0;
    accumulationSteps = 4; (* Gradient accumulation *)
    
    (* Process batches *)
    Do[
        Module[{batch, batchLoss, batchMetrics, scaledLoss, gradients},
            batch = GetBatch[trainData, config["batchSize"], i];
            
            (* Forward pass *)
            If[scaler =!= Null,
                (* Mixed precision forward pass *)
                With[{autocast = True},
                    predictions = model[batch[[1]]];
                    batchLoss = lossFunction[batch[[2]], predictions];
                    scaledLoss = scaler.Scale[batchLoss];
                ],
                (* Standard forward pass *)
                predictions = model[batch[[1]]];
                batchLoss = lossFunction[batch[[2]], predictions];
                scaledLoss = batchLoss;
            ];
            
            (* Backward pass *)
            gradients = Grad[scaledLoss, model.Parameters[]];
            
            (* Gradient accumulation *)
            If[Mod[i, accumulationSteps] == 0,
                If[scaler =!= Null,
                    scaler.Step[optimizer, gradients];
                    scaler.Update[];
                ,
                    optimizer.Step[gradients];
                ];
                optimizer.ZeroGrad[];
            ];
            
            (* Update metrics *)
            totalLoss += batchLoss;
            batchMetrics = Map[#[batch[[2]], predictions] &, metrics];
            totalMetrics += batchMetrics;
            batchCount++;
        ],
        {i, 1, GetBatchCount[trainData, config["batchSize"]]}
    ];
    
    avgLoss = totalLoss / batchCount;
    avgMetrics = totalMetrics / batchCount;
    
    {avgLoss, AssociationThread[{"accuracy", "precision", "recall", "f1"}, avgMetrics]}
];

(* Validation epoch *)
ValidateEpoch[model_, valData_, lossFunction_, metrics_] := Module[
    {totalLoss, totalMetrics, batchCount},
    
    totalLoss = 0.0;
    totalMetrics = Map[0.0 &, metrics];
    batchCount = 0;
    
    (* Process validation batches *)
    Do[
        Module[{batch, predictions, batchLoss, batchMetrics},
            batch = GetBatch[valData, 128, i]; (* Fixed batch size for validation *)
            
            (* Forward pass only *)
            predictions = model[batch[[1]]];
            batchLoss = lossFunction[batch[[2]], predictions];
            
            (* Update metrics *)
            totalLoss += batchLoss;
            batchMetrics = Map[#[batch[[2]], predictions] &, metrics];
            totalMetrics += batchMetrics;
            batchCount++;
        ],
        {i, 1, GetBatchCount[valData, 128]}
    ];
    
    avgLoss = totalLoss / batchCount;
    avgMetrics = totalMetrics / batchCount;
    
    {avgLoss, AssociationThread[{"accuracy", "precision", "recall", "f1"}, avgMetrics]}
];

(* =========================== MODEL EVALUATION =========================== *)

(* Comprehensive model evaluation *)
EvaluateModel[model_, testData_Association] := Module[
    {predictions, trueLabels, accuracy, precision, recall, f1, confusionMatrix, 
     classificationReport, rocCurves, calibrationCurve},
    
    Log["INFO", "Evaluating model on test set"];
    
    (* Generate predictions *)
    model.SetTraining[False];
    predictions = model[testData["test"][[1]]];
    trueLabels = testData["test"][[2]];
    
    (* Calculate metrics *)
    accuracy = Accuracy[trueLabels, predictions];
    precision = Precision[trueLabels, predictions, "average" -> "weighted"];
    recall = Recall[trueLabels, predictions, "average" -> "weighted"];
    f1 = F1Score[trueLabels, predictions, "average" -> "weighted"];
    
    (* Confusion matrix *)
    confusionMatrix = ConfusionMatrix[trueLabels, predictions];
    
    (* Per-class metrics *)
    classificationReport = Table[
        {
            "class" -> class,
            "precision" -> Precision[trueLabels, predictions, "labels" -> {class}],
            "recall" -> Recall[trueLabels, predictions, "labels" -> {class}],
            "f1" -> F1Score[trueLabels, predictions, "labels" -> {class}],
            "support" -> Count[trueLabels, class]
        },
        {class, testData["classes"]}
    ];
    
    (* ROC curves for multi-class *)
    rocCurves = Table[
        ROCCurve[
            Map[If[# == class, 1, 0] &, trueLabels],
            predictions[[All, class + 1]] (* Softmax probabilities *)
        ],
        {class, testData["classes"]}
    ];
    
    (* Model calibration *)
    calibrationCurve = CalibrationCurve[trueLabels, predictions];
    
    (* Top-k accuracy *)
    top5Accuracy = TopKAccuracy[trueLabels, predictions, 5];
    
    Log["INFO", "Model evaluation complete"];
    Log["INFO", "Test Accuracy: " <> ToString[Round[accuracy * 100, 0.1]] <> "%"];
    Log["INFO", "Test F1-Score: " <> ToString[Round[f1, 0.001]]];
    
    {
        "accuracy" -> accuracy,
        "precision" -> precision,
        "recall" -> recall,
        "f1" -> f1,
        "top5_accuracy" -> top5Accuracy,
        "confusion_matrix" -> confusionMatrix,
        "classification_report" -> classificationReport,
        "roc_curves" -> rocCurves,
        "calibration_curve" -> calibrationCurve,
        "predictions" -> predictions,
        "true_labels" -> trueLabels
    }
];

(* =========================== HYPERPARAMETER TUNING =========================== *)

(* Bayesian optimization for hyperparameter tuning *)
HyperparameterTuning[dataset_Association, searchSpace_Association, trials_Integer:50] := Module[
    {optimizer, bestParams, bestScore, history, trialResults},
    
    Log["INFO", "Starting hyperparameter optimization"];
    
    optimizer = BayesianOptimizer[
        "searchSpace" -> searchSpace,
        "acquisitionFunction" -> "ExpectedImprovement",
        "gaussianProcess" -> "Matern52"
    ];
    
    bestScore = -Infinity;
    bestParams = {};
    history = {};
    
    Do[
        Module[{params, model, trainResult, valScore, trial},
            (* Sample hyperparameters *)
            params = optimizer.SuggestParams[];
            
            Log["INFO", "Trial " <> ToString[trial] <> ": " <> ToString[params]];
            
            (* Build and train model with suggested params *)
            model = BuildResNet18[dataset["inputShape"], 
                                 Length[dataset["classes"]], params["dropout"]];
            
            (* Quick training for hyperparameter search *)
            trainResult = TrainModel[model, dataset, 
                Join[config, params, {"epochs" -> 20}]];
            
            (* Evaluate on validation set *)
            valScore = Last[trainResult["history"]["valAcc"]];
            
            (* Update optimizer *)
            optimizer.ReportResult[params, valScore];
            
            (* Track best parameters *)
            If[valScore > bestScore,
                bestScore = valScore;
                bestParams = params;
            ];
            
            AppendTo[history, {
                "trial" -> trial,
                "params" -> params,
                "score" -> valScore,
                "training_time" -> trainResult["trainingTime"]
            }];
            
            Log["INFO", "Trial " <> ToString[trial] <> " - Val Acc: " <> 
                        ToString[Round[valScore * 100, 0.1]] <> "%"];
        ],
        {trial, 1, trials}
    ];
    
    Log["INFO", "Hyperparameter optimization complete"];
    Log["INFO", "Best parameters: " <> ToString[bestParams]];
    Log["INFO", "Best validation accuracy: " <> ToString[Round[bestScore * 100, 0.1]] <> "%"];
    
    {
        "best_params" -> bestParams,
        "best_score" -> bestScore,
        "history" -> history,
        "optimizer" -> optimizer
    }
];

(* =========================== MODEL DEPLOYMENT =========================== *)

(* Production deployment utilities *)
DeployModel[model_, metadata_Association, deploymentConfig_Association] := Module[
    {modelVersion, deploymentPath, optimizedModel, servingFunction},
    
    Log["INFO", "Preparing model for deployment"];
    
    (* Version the model *)
    modelVersion = DateFormat[Now[], "YYYYMMDD_HHMMSS"];
    deploymentPath = "models/production/v" <> modelVersion;
    
    (* Optimize model for inference *)
    optimizedModel = OptimizeForInference[model, {
        "quantization" -> deploymentConfig["quantization"],
        "pruning" -> deploymentConfig["pruning"],
        "tensorrt" -> deploymentConfig["tensorrt"]
    }];
    
    (* Create serving function *)
    servingFunction = Function[{inputBatch},
        Module[{preprocessed, predictions, postprocessed},
            (* Preprocess input *)
            preprocessed = PreprocessForInference[inputBatch];
            
            (* Generate predictions *)
            predictions = optimizedModel[preprocessed];
            
            (* Postprocess output *)
            postprocessed = PostprocessPredictions[predictions];
            
            {
                "predictions" -> postprocessed,
                "confidence" -> Max[predictions, 2], (* Max prob per sample *)
                "model_version" -> modelVersion,
                "timestamp" -> Now[]
            }
        ]
    ];
    
    (* Save deployment artifacts *)
    Export[deploymentPath <> "/model.onnx", optimizedModel, "ONNX"];
    Export[deploymentPath <> "/metadata.json", 
           JSONStringify[Join[metadata, {"version" -> modelVersion}]]];
    Export[deploymentPath <> "/serving_function.wl", servingFunction];
    
    (* Create model registry entry *)
    RegisterModel[{
        "name" -> "image_classifier",
        "version" -> modelVersion,
        "path" -> deploymentPath,
        "accuracy" -> metadata["accuracy"],
        "deployment_date" -> Now[],
        "status" -> "active"
    }];
    
    Log["INFO", "Model deployed successfully - Version: " <> modelVersion];
    
    {
        "version" -> modelVersion,
        "path" -> deploymentPath,
        "serving_function" -> servingFunction,
        "optimized_model" -> optimizedModel
    }
];

(* Batch inference for production *)
BatchInference[modelPath_String, inputBatch_List, batchSize_Integer:32] := Module[
    {model, results, processingTime},
    
    processingTime = AbsoluteTime[];
    
    (* Load production model *)
    model = Import[modelPath <> "/model.onnx"];
    
    (* Process in batches *)
    results = Map[
        Function[batch,
            Module[{predictions, confidence},
                predictions = model[batch];
                confidence = Map[Max, predictions];
                
                Map[{
                    "prediction" -> #[[1]],
                    "confidence" -> #[[2]],
                    "timestamp" -> Now[]
                } &, Transpose[{predictions, confidence}]]
            ]
        ],
        Partition[inputBatch, batchSize]
    ];
    
    processingTime = AbsoluteTime[] - processingTime;
    
    Log["INFO", "Batch inference complete - " <> ToString[Length[inputBatch]] <> 
                " samples in " <> ToString[Round[processingTime, 0.1]] <> " seconds"];
    
    Flatten[results, 1]
];

(* =========================== MAIN WORKFLOW =========================== *)

(* Execute complete ML workflow *)
RunMLWorkflow[] := Module[
    {dataset, model, trainingResult, evaluation, hyperparamResult, deployment, 
     workflowStartTime, totalTime},
    
    workflowStartTime = AbsoluteTime[];
    
    Log["INFO", "=== STARTING MACHINE LEARNING WORKFLOW ==="];
    
    Try[
        (* 1. Data Preparation *)
        dataset = PrepareDataset[config["datasetPath"], config];
        
        (* 2. Model Architecture *)
        model = Switch[modelConfig["architecture"],
            "ResNet18", BuildResNet18[dataset["inputShape"], 
                                     Length[dataset["classes"]], 
                                     modelConfig["dropout"]],
            "ViT", BuildVisionTransformer[dataset["inputShape"], 
                                         Length[dataset["classes"]]],
            _, BuildResNet18[dataset["inputShape"], 
                            Length[dataset["classes"]], 
                            modelConfig["dropout"]]
        ];
        
        (* 3. Hyperparameter Tuning (optional) *)
        If[KeyExistsQ[config, "tuneHyperparams"] && config["tuneHyperparams"],
            hyperparamResult = HyperparameterTuning[dataset, hyperparamSpace, 20];
            config = Join[config, hyperparamResult["best_params"]];
        ];
        
        (* 4. Model Training *)
        trainingResult = TrainModel[model, dataset, config];
        
        (* 5. Model Evaluation *)
        evaluation = EvaluateModel[trainingResult["model"], dataset];
        
        (* 6. Model Deployment *)
        deployment = DeployModel[trainingResult["model"], 
            Join[evaluation, trainingResult], 
            {"quantization" -> True, "pruning" -> False, "tensorrt" -> False}
        ];
        
        totalTime = AbsoluteTime[] - workflowStartTime;
        
        Log["INFO", "=== ML WORKFLOW COMPLETE ==="];
        Log["INFO", "Total execution time: " <> ToString[Round[totalTime / 60, 0.1]] <> " minutes"];
        Log["INFO", "Final test accuracy: " <> ToString[Round[evaluation["accuracy"] * 100, 0.1]] <> "%"];
        
        (* Return workflow results *)
        {
            "status" -> "SUCCESS",
            "execution_time" -> totalTime,
            "model" -> trainingResult["model"],
            "training_history" -> trainingResult["history"],
            "evaluation" -> evaluation,
            "deployment" -> deployment,
            "hyperparams" -> If[Exists[hyperparamResult], hyperparamResult, {}]
        }
    ,
        error_ :> Module[{},
            Log["ERROR", "ML workflow failed: " <> ToString[error]];
            {
                "status" -> "FAILED",
                "error" -> error,
                "execution_time" -> AbsoluteTime[] - workflowStartTime
            }
        ]
    ]
];

(* =========================== EXECUTION =========================== *)

(* Execute the ML workflow *)
mlResults = RunMLWorkflow[];

(* Display results summary *)
Print["Machine Learning Workflow Results:"];
Print["Status: " <> mlResults["status"]];
Print["Execution Time: " <> ToString[Round[mlResults["execution_time"] / 60, 0.1]] <> " minutes"];
If[mlResults["status"] == "SUCCESS",
    Print["Test Accuracy: " <> ToString[Round[mlResults["evaluation"]["accuracy"] * 100, 0.1]] <> "%"];
    Print["F1-Score: " <> ToString[Round[mlResults["evaluation"]["f1"], 0.003]]];
    Print["Model Version: " <> mlResults["deployment"]["version"]];
    Print["Training Epochs: " <> ToString[Length[mlResults["training_history"]["trainLoss"]]]];
];

(* Example output:
Machine Learning Workflow Results:
Status: SUCCESS
Execution Time: 89.3 minutes
Test Accuracy: 94.2%
F1-Score: 0.941
Model Version: 20241101_143022
Training Epochs: 67
*)